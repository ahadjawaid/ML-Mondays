{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Deployment"
      ],
      "metadata": {
        "id": "da2s686IaPnF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing our required dependencies"
      ],
      "metadata": {
        "id": "RgLJDMLpafpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --quiet gradio\n",
        "! pip install -Uqq fastai"
      ],
      "metadata": {
        "id": "8ET47qXn7_i4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- fastai --> the library that gives us access to deep learning models and functions so we do not have to implement them by scratch ourselves\n",
        "- duckduckgo_search --> this library allows us to automate searching the duckduckgo broswer and in this case, pulling the images from the internet\n",
        "- time --> this library allows us to measure time elapsed, pause the program for a certain period of time, and various other time-related functions\n",
        "- pathlib --> this library allows us to manipulate file paths in our systems\n",
        "- gradio --> this library is used to quickly building a simple web application for machine(deep) learning models"
      ],
      "metadata": {
        "id": "zRlp75Yh8MtI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lomhLRRR73ym"
      },
      "outputs": [],
      "source": [
        "from fastai.vision.all import *\n",
        "from duckduckgo_search import ddg_images\n",
        "from fastcore.all import *\n",
        "from fastdownload import download_url\n",
        "from time import sleep\n",
        "from pathlib import Path\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making our dataset"
      ],
      "metadata": {
        "id": "Q5biWPfsOgE7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we will be making our own image classification dataset. Run the code below to enter the categories you would like the model to be trained on."
      ],
      "metadata": {
        "id": "SPSIeRR4K66m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search_terms = []\n",
        "while True:\n",
        "    term = input(\"Enter a category that you would like as part of the image dataset. Enter \\\"done\\\" to quit.\")\n",
        "    if term.lower() == \"done\":\n",
        "        break\n",
        "    search_terms.append(term)"
      ],
      "metadata": {
        "id": "tWxMLNbX9fMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to set the path for our data folder and make the folder itself if it does not already exist."
      ],
      "metadata": {
        "id": "drpilkitLIFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = Path(\"data\")\n",
        "output_dir.mkdir(exist_ok=True, parents=True)"
      ],
      "metadata": {
        "id": "1LC3q2GELHhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the code below to enter how many images you want each category to contains."
      ],
      "metadata": {
        "id": "S0pAucw2LS8H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note, that the number you enter might not be how many images each category will actually contain. This is because some of the images we get from the internet may be corrupt and we would have to get rid of them."
      ],
      "metadata": {
        "id": "3m4y-_PfL6n5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_images = int(input(\"Enter the maximum number of images you would like to have for each category.\"))"
      ],
      "metadata": {
        "id": "u4Q2znbJLSSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code block uses duckduckgo_search to get the images from the internet and then downloads them into the data folder. Seperate folders are also created for each category and the images will go to their respestive category."
      ],
      "metadata": {
        "id": "ysGc1Zm4L_eC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The file architecture will look something like this:\n",
        "\n",
        "Data:\n",
        "- Category 1:\n",
        "    - Image 1\n",
        "    - Image 2\n",
        "- Category 2:\n",
        "    - Image 1\n",
        "    - Image 2\n"
      ],
      "metadata": {
        "id": "mrTZ3TmdMRD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for term in search_terms:\n",
        "    # Create folder for search term\n",
        "    dest = (output_dir/term)\n",
        "    dest.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    # Searchs for images and gets urls\n",
        "    urls = L(ddg_images(term, max_results=max_images)).itemgot(\"image\")\n",
        "\n",
        "    # Trys downloading images from url\n",
        "    for url in urls:\n",
        "        try:\n",
        "            download_url(url, dest, show_progress=False)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    # Resizes images\n",
        "    resize_images(dest, max_size=400, dest=dest)"
      ],
      "metadata": {
        "id": "jt4HWTneL8fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we are taking the images from the internet, we would like to keep track of which images failed to download."
      ],
      "metadata": {
        "id": "LJa6vpyaM00b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "failed = verify_images(get_image_files(output_dir))\n",
        "failed.map(Path.unlink)\n",
        "len(failed)"
      ],
      "metadata": {
        "id": "5_om9l8PM0YR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code block is basically taking all of our images and performing some operation on it in one batch. It is then stored as one object."
      ],
      "metadata": {
        "id": "ZHEOjHTeZ78E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dls = DataBlock(\n",
        "    blocks=(ImageBlock, CategoryBlock),\n",
        "    get_items=get_image_files,\n",
        "    splitter=RandomSplitter(valid_pct=0.2),\n",
        "    get_y=parent_label,\n",
        "    item_tfms=[Resize(128, method=\"squish\")],\n",
        ").dataloaders(output_dir, bs=20)\n",
        "\n",
        "dls.show_batch(max_n=6)"
      ],
      "metadata": {
        "id": "SEJ5htGGM-v0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training, Evaluating, and Saving our Model"
      ],
      "metadata": {
        "id": "MTbSSXoJQSdN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we get to create and train our model."
      ],
      "metadata": {
        "id": "jIyPTtr2NCu9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that in this case, we are \"fine-tuning\" our model. This basically just means that we are taking a pretrained model and then training it again on a smaller dataset. This is helpful because we do not have to train our own model from scratch and only worry about using a pretrained model and training it for our specific use case."
      ],
      "metadata": {
        "id": "zCbKWsJ4NM26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn = vision_learner(dls, resnet18, metrics=[accuracy, error_rate])\n",
        "learn.fine_tune(4)"
      ],
      "metadata": {
        "id": "-y-3_HaENCLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get a better understanding of where the model misclassified and how we can see what the model classified with a confusion matrix and by seeing which item the model was most confused about."
      ],
      "metadata": {
        "id": "oiI8miuwQn3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "interp.plot_confusion_matrix()"
      ],
      "metadata": {
        "id": "nBdrvaevQcQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "interp.plot_top_losses(1, nrows=2)"
      ],
      "metadata": {
        "id": "GT9iae5lQfQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If our model performs well, then it always good practice to save/export our model."
      ],
      "metadata": {
        "id": "IdLOvCX-OGwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn.export('model.pkl')"
      ],
      "metadata": {
        "id": "DOGB_wUnOCXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Deployment"
      ],
      "metadata": {
        "id": "ubYNHFReOZ8z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is the function that our web server will call when we want an inference made."
      ],
      "metadata": {
        "id": "fdhjrobpRHVw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference is basically when we want a model to predict something. In this case, that is classifying an image."
      ],
      "metadata": {
        "id": "gEs2Qs1rRQ4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categories = search_terms\n",
        "def classify_image(image):\n",
        "    pred, i, prob = learn.predict(image)\n",
        "    return dict(zip(categories, map(float, prob)))"
      ],
      "metadata": {
        "id": "U7Js3rZyOU7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code starts up the local server where our model is running. We can run inference on our model without any more code and a cleaner UI."
      ],
      "metadata": {
        "id": "ta-3VT5dQuyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = gr.inputs.Image(shape=(192, 192))\n",
        "label = gr.outputs.Label()\n",
        "\n",
        "interface = gr.Interface(fn=classify_image, inputs=image, outputs=label)\n",
        "interface.launch(inline=False)"
      ],
      "metadata": {
        "id": "eyB36wNFOXvL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}